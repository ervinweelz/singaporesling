{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SINGAPORE: The licence of Proofer Bakery & Pizzeria’s outlet at Changi City Point has been suspended for two weeks due to its failure to keep its licensed premises free of infestation, said Singapore Food Agency (SFA) on Wednesday (Jul 12).\n",
      "The branch will not be allowed to operate from Jul 12 to Jul 25. \n",
      "Proofer was also fined S$800 (US$599) after accumulating 12 demerit points in a year. It was given six demerit points each for two offences of failing to keep licensed premises free of infestation. \n",
      "Under the SFA’s points system, a licensee who accumulates 12 or more demerit points during a 12-month period may have their licence suspended for a period of either two or four weeks, or cancelled.\n",
      "\"All food handlers working in the suspended premises would also be required to re-attend and pass the Food Safety Course Level 1, before they can resume work as food handlers,\" said the agency. \n",
      "The licensee is also required to ensure that all food hygiene officers working in the suspended premises, if any, re-attend and pass the Food Safety Course Level 3.\n",
      "SFA said it takes a serious view of these offences and reminded food operators to observe good food and personal hygiene practices at all times, and to engage only registered food handlers.\n",
      "The agency added it will not hesitate to take firm action against anyone found to be in violation of the Environmental Public Health Act.\n",
      "The central kitchen of Proofer Bakery was previously suspended after a “massive pest infestation” was detected by inspectors in October 2021. Food products distributed to Proofer’s retail outlets islandwide were also then recalled.\n",
      "In response to CNA's query, SFA said the suspension of Proofer's Changi City Point outlet is the first since the suspension of the central kitchen.\n",
      "Members of the public who come across poor food safety practices in food establishments are advised not to patronise the outlets. \n",
      "They can also provide feedback to SFA via its online feedback form or its contact centre at 6805 2871 with details for follow-up investigations. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finance\n",
    "# url = 'https://www.channelnewsasia.com/singapore/mas-record-net-loss-s308-billion-annual-report-sing-dollar-inflation-higher-interest-3606691'\n",
    "# url = 'https://www.channelnewsasia.com/world/china-uk-discriminatory-actions-linked-deals-3623826'\n",
    "#Tech\n",
    "# url = 'https://www.channelnewsasia.com/business/google-ai-health-chatbot-passes-us-medical-exam-study-3624546'\n",
    "# url = 'https://www.channelnewsasia.com/business/shopify-launch-ai-assistant-merchants-3624511'\n",
    "# url = 'https://www.channelnewsasia.com/business/elon-musk-thinks-china-interested-international-ai-framework-3625416'\n",
    "# url = 'https://www.channelnewsasia.com/commentary/ai-chatgpt-large-language-models-fake-news-fact-checking-3623186'\n",
    "# url = 'https://www.channelnewsasia.com/business/ai-explosion-merits-regulation-rein-threats-experts-say-3625266'\n",
    "#Military\n",
    "# url = 'https://www.channelnewsasia.com/world/why-dont-some-nato-countries-want-ukraine-join-3623341'\n",
    "# url = 'https://www.channelnewsasia.com/asia/more-submarines-jets-indian-navy-cards-modi-visits-france-3623756'\n",
    "#Food\n",
    "# url = 'https://www.channelnewsasia.com/commentary/supermarket-plastic-bag-ban-singapore-packaging-waste-sustainability-3606836'\n",
    "# url = 'https://www.channelnewsasia.com/singapore/chicken-rice-e-coli-youtube-video-stringent-checks-sfa-3550506'\n",
    "# url = 'https://www.channelnewsasia.com/singapore/urban-rooftop-farming-vegetables-greens-unsold-leftover-lack-support-3623701'\n",
    "# url = 'https://www.channelnewsasia.com/world/united-nations-world-track-meet-2030-goal-3624306'\n",
    "#Singapore\n",
    "# url = 'https://www.channelnewsasia.com/singapore/iswaran-cpib-assist-investigations-ongoing-pm-lee-3622586'\n",
    "# url = 'https://www.channelnewsasia.com/singapore/iswaran-cpib-investigation-leave-absence-mps-west-coast-lawrence-wong-3622871'\n",
    "url = 'https://www.channelnewsasia.com/singapore/proofer-bakery-pizzeria-suspended-two-weeks-changi-city-point-sfa-infestation-licence-3624036'\n",
    "\n",
    "article = Article(url)\n",
    "article.download()\n",
    "html_content = article.html\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "article_elements = soup.find_all(['div'], class_=['text'])  # Replace with the appropriate element\n",
    "article_text = \"\"\n",
    "for element in article_elements:\n",
    "  article_text += element.get_text()\n",
    "print(article_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is KeyBert :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('safety practices food', 0.3704), ('licensee required ensure', 0.3766), ('period licence suspended', 0.3815), ('proofer changi city', 0.385), ('infestation said singapore', 0.397), ('food handlers working', 0.3987), ('proofer bakery pizzeria', 0.4142), ('points licensee accumulates', 0.4385), ('demerit points offences', 0.4423), ('bakery previously suspended', 0.4562)]\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT()\n",
    "# vectorizer = KeyBERT.CountVectorizer(ngram_range=(1, 3), stop_words=\"english\")\n",
    "# keywords = kw_model.extract_keywords(article.text, keyphrase_ngram_range=(3, 3), stop_words='english',use_maxsum=True, nr_candidates=20, top_n= 10)\n",
    "keywords = kw_model.extract_keywords(article_text, keyphrase_ngram_range=(3, 3), stop_words='english',use_maxsum=True, nr_candidates=30, top_n= 10)\n",
    "# keywords = kw_model.extract_keywords(article_text, keyphrase_ngram_range=(3, 3), stop_words='english', use_mmr=True, diversity=0.7, top_n= 10)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is Bart :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# pipe = pipeline(\"text-classification\", model=\"facebook/bart-large-cnn\")\n",
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pipe(article_text, min_length = 5, do_sample = False))\n",
    "print(pipe(article_text,max_length=130, min_length=30, do_sample = False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is Spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def get_hotwords(text):\n",
    "    result = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] \n",
    "    doc = nlp(text.lower()) \n",
    "    for token in doc:\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        if(token.pos_ in pos_tag):\n",
    "            result.append(token.text)\n",
    "    return result\n",
    "output = set(get_hotwords(article_text))\n",
    "most_common_list = Counter(output).most_common(10)\n",
    "for item in most_common_list:\n",
    "  print(item[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is VLT5 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[0;32m      3\u001b[0m pipe \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39mtext2text-generation\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mVoicelab/vlt5-base-keywords\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\utils\\import_utils.py:1076\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[0;32m   1075\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m-> 1076\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[0;32m   1077\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1078\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\utils\\import_utils.py:1086\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1084\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_module\u001b[39m(\u001b[39mself\u001b[39m, module_name: \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1085\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1086\u001b[0m         \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[0;32m   1087\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1088\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1089\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1090\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1091\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\pipelines\\__init__.py:60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconversational\u001b[39;00m \u001b[39mimport\u001b[39;00m Conversation, ConversationalPipeline\n\u001b[0;32m     59\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdepth_estimation\u001b[39;00m \u001b[39mimport\u001b[39;00m DepthEstimationPipeline\n\u001b[1;32m---> 60\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdocument_question_answering\u001b[39;00m \u001b[39mimport\u001b[39;00m DocumentQuestionAnsweringPipeline\n\u001b[0;32m     61\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction\u001b[39;00m \u001b[39mimport\u001b[39;00m FeatureExtractionPipeline\n\u001b[0;32m     62\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfill_mask\u001b[39;00m \u001b[39mimport\u001b[39;00m FillMaskPipeline\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\pipelines\\document_question_answering.py:29\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     ExplicitEnum,\n\u001b[0;32m     22\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     logging,\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m PIPELINE_INIT_ARGS, ChunkPipeline\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mquestion_answering\u001b[39;00m \u001b[39mimport\u001b[39;00m select_starts_ends\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m is_vision_available():\n\u001b[0;32m     33\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\pipelines\\question_answering.py:8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING, Dict, List, Optional, Tuple, Union\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m SquadExample, SquadFeatures, squad_convert_examples_to_features\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodelcard\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelCard\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenization_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m PreTrainedTokenizer\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\data\\__init__.py:26\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata_collator\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     DataCollatorForLanguageModeling,\n\u001b[0;32m     17\u001b[0m     DataCollatorForPermutationLanguageModeling,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     default_data_collator,\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m glue_compute_metrics, xnli_compute_metrics\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mprocessors\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     DataProcessor,\n\u001b[0;32m     29\u001b[0m     InputExample,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     xnli_tasks_num_labels,\n\u001b[0;32m     44\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\data\\metrics\\__init__.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_sklearn_available, requires_backends\n\u001b[0;32m     18\u001b[0m \u001b[39mif\u001b[39;00m is_sklearn_available():\n\u001b[1;32m---> 19\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m pearsonr, spearmanr\n\u001b[0;32m     20\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m f1_score, matthews_corrcoef\n\u001b[0;32m     23\u001b[0m DEPRECATION_WARNING \u001b[39m=\u001b[39m (\n\u001b[0;32m     24\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mThis metric will be removed from the library soon, metrics should be handled with the 🤗 Evaluate \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlibrary. You can have a look at this example script for pointers: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\stats\\__init__.py:608\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m \n\u001b[0;32m    604\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_warnings_errors\u001b[39;00m \u001b[39mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    607\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 608\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    609\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_variation\u001b[39;00m \u001b[39mimport\u001b[39;00m variation\n\u001b[0;32m    610\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdistributions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\stats\\_stats_py.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m \u001b[39mimport\u001b[39;00m NumpyVersion\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m suppress_warnings\n\u001b[1;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspatial\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistance\u001b[39;00m \u001b[39mimport\u001b[39;00m cdist\n\u001b[0;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mndimage\u001b[39;00m \u001b[39mimport\u001b[39;00m _measurements\n\u001b[0;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_util\u001b[39;00m \u001b[39mimport\u001b[39;00m (check_random_state, MapWrapper, _get_nan,\n\u001b[0;32m     42\u001b[0m                               rng_integers, _rename_parameter, _contains_nan)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\spatial\\__init__.py:110\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m=============================================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mSpatial algorithms and data structures (:mod:`scipy.spatial`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39m   QhullError\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_kdtree\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_ckdtree\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    112\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_qhull\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\spatial\\_kdtree.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright Anne M. Archibald 2008\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Released under the scipy license\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_ckdtree\u001b[39;00m \u001b[39mimport\u001b[39;00m cKDTree, cKDTreeNode\n\u001b[0;32m      6\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mminkowski_distance_p\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mminkowski_distance\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mdistance_matrix\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mRectangle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mKDTree\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminkowski_distance_p\u001b[39m(x, y, p\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m):\n",
      "File \u001b[1;32m_ckdtree.pyx:12\u001b[0m, in \u001b[0;36minit scipy.spatial._ckdtree\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\sparse\\__init__.py:287\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_matrix_io\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    286\u001b[0m \u001b[39m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m csgraph\n\u001b[0;32m    289\u001b[0m \u001b[39m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    291\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[0;32m    292\u001b[0m     lil, sparsetools, sputils\n\u001b[0;32m    293\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\sparse\\csgraph\\__init__.py:185\u001b[0m\n\u001b[0;32m    157\u001b[0m __docformat__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrestructuredtext en\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mconnected_components\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    160\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mlaplacian\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    161\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mshortest_path\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mcsgraph_to_masked\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    183\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mNegativeCycleError\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m--> 185\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_laplacian\u001b[39;00m \u001b[39mimport\u001b[39;00m laplacian\n\u001b[0;32m    186\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_shortest_path\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    187\u001b[0m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson,\n\u001b[0;32m    188\u001b[0m     NegativeCycleError\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    190\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_traversal\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    191\u001b[0m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[0;32m    192\u001b[0m     depth_first_tree, connected_components\n\u001b[0;32m    193\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\sparse\\csgraph\\_laplacian.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m issparse\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearOperator\n\u001b[0;32m     10\u001b[0m \u001b[39m###############################################################################\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# Graph laplacian\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlaplacian\u001b[39m(\n\u001b[0;32m     13\u001b[0m     csgraph,\n\u001b[0;32m     14\u001b[0m     normed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     symmetrized\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\sparse\\linalg\\__init__.py:120\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m==================================================\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \n\u001b[0;32m    118\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_isolve\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    121\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dsolve\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_interface\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\sparse\\linalg\\_isolve\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mIterative Solvers for Sparse Linear Systems\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39m#from info import __doc__\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39miterative\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mminres\u001b[39;00m \u001b[39mimport\u001b[39;00m minres\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlgmres\u001b[39;00m \u001b[39mimport\u001b[39;00m lgmres\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\sparse\\linalg\\_isolve\\iterative.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtextwrap\u001b[39;00m \u001b[39mimport\u001b[39;00m dedent\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _iterative\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_interface\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearOperator\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m make_system\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=\"Voicelab/vlt5-base-keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe(article_text,max_length=130, min_length=30, do_sample = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGAPORE: The Monetary Authority of Singapore (MAS) recorded its largest net loss of S$30.8 billion (US$22.8 billion) in the financial year that ended Mar 31, widening significantly from a S$7.4 billion loss in the year before that.This was largely because of the central bank’s aggressive monetary policy tightening to bring down inflation, which paved the way for a “broad appreciation” of the Singapore dollar against other currencies – such as the US dollar, euro and yen – that the official foreign reserves were held in.As MAS’ financial results are reported in the Sing dollar, it saw “significant” negative currency translation effects of about S$21.4 billion, or 70 per cent of the annual net loss, MAS managing director Ravi Menon said on Wednesday (Jul 5). \n",
      " ---> Singapore, financial results, monetary policy,\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Voicelab/vlt5-base-keywords\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Voicelab/vlt5-base-keywords\")\n",
    "\n",
    "task_prefix = \"Keywords: \"\n",
    "inputs = [\n",
    "    \"SINGAPORE: The Monetary Authority of Singapore (MAS) recorded its largest net loss of S$30.8 billion (US$22.8 billion) in the financial year that ended Mar 31, widening significantly from a S$7.4 billion loss in the year before that.This was largely because of the central bank’s aggressive monetary policy tightening to bring down inflation, which paved the way for a “broad appreciation” of the Singapore dollar against other currencies – such as the US dollar, euro and yen – that the official foreign reserves were held in.As MAS’ financial results are reported in the Sing dollar, it saw “significant” negative currency translation effects of about S$21.4 billion, or 70 per cent of the annual net loss, MAS managing director Ravi Menon said on Wednesday (Jul 5).\",\n",
    "]\n",
    "\n",
    "for sample in inputs:\n",
    "    input_sequences = [task_prefix + sample]\n",
    "    input_ids = tokenizer(\n",
    "        input_sequences, return_tensors=\"pt\", truncation=True,max_length=512,\n",
    "    ).input_ids\n",
    "    output = model.generate(input_ids, no_repeat_ngram_size=3, num_beams=4)\n",
    "    predicted = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(sample, \"\\n --->\", predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monetary Authority of Singapore (MAS), investment gain, investment performance\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Voicelab/vlt5-base-keywords\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"Voicelab/vlt5-base-keywords\")\n",
    "\n",
    "task_prefix = \"Keywords: \"\n",
    "\n",
    "\n",
    "input_sequences = [task_prefix + article_text]\n",
    "input_ids = tokenizer(\n",
    "    input_sequences, return_tensors=\"pt\", truncation=True,max_length=512,\n",
    ").input_ids\n",
    "output = model.generate(input_ids,max_length=100, no_repeat_ngram_size=5, num_beams=10)\n",
    "predicted = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monetary Authority of Singapore (MAS), investment gain, investment performance\n"
     ]
    }
   ],
   "source": [
    "# output = model.generate(input_ids, no_repeat_ngram_size=5, num_beams=4)\n",
    "output = model.generate(input_ids,max_length=100, no_repeat_ngram_size=5, num_return_sequences=5,num_beams=8)\n",
    "\n",
    "predicted = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Voicelab/vlt5-base-keywords\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Voicelab/vlt5-base-keywords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monetary Authority of Singapore (MAS), investment gain, investment performance\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Keywords: \" + article_text,\n",
    "return_tensors='pt',\n",
    "max_length=512,\n",
    "truncation=True)\n",
    "# summary_ids = model.generate(inputs, max_length=150, min_length=3, length_penalty=5., num_beams=2)\n",
    "# summary_ids = model.generate(inputs, no_repeat_ngram_size=5, num_beams=4) # Singapore, financial results, investment gain\n",
    "summary_ids = model.generate(inputs, max_length=100, no_repeat_ngram_size=5, num_return_sequences=5,num_beams=8) # Monetary Authority of Singapore (MAS), investment gain, investment performance\n",
    "\n",
    "\n",
    "\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3232,   273,  4722,  8844,   291,   365, 19679,  8943,  3759,   727,\n",
       "           291,   720,   432,   873,  2144, 22390,  5685,  3936,   730,   365,\n",
       "          9626,  2087,   275,   269, 23399,   293,   896, 11177,  1216,   264,\n",
       "          3745,   277,  2614, 18941,   277,  1331,  3298,   307,   730,   365,\n",
       "          2098,   901,   259,  1128,  1199,  8732,   627,   269,  8244,  2098,\n",
       "          1153,   259,  1128,  1199,  8732,   627,   293,   762,  1237, 23757,\n",
       "          6839,   756,   277,   273,   275,   748, 19962,   879, 24537,  1216,\n",
       "          1024,   753,   261,   260,  6301,  7144,   414,  9313, 24714,  1522,\n",
       "          2944, 21837,   287,   365,  2098,  1083,   259,   776,  1199,  8732,\n",
       "           627,  3298,   307,   762,  1237,   277,   273,   275,   748,  4660,\n",
       "          5327,   275, 19962,   879,   259, 28240, 19048,   277,  2614,  6776,\n",
       "           273,  4660,   518, 11733,   730,  1237, 11968,  4313,  6249,   307,\n",
       "           287,  5076, 23972,  9377, 10405,  2144,   292, 16278,  1431,  6176,\n",
       "           275,  7144,   294,  1749,   907,   272, 11669,   762,  5172,  4072,\n",
       "           261,   260,  2217,   282,  2305, 24097,  1237,   260,   267,   273,\n",
       "          3643,   287,  8549,  3719,  1638,   287,   393,  6618,   833,  4072,\n",
       "           510,   730,  1237,   365,  9626,  2087,   275,   272,   524,  2614,\n",
       "         25157,   329,   717,   284,  4310, 26897,  3840,   526,   307,   308,\n",
       "          2674,   282, 11623,  1237,  3830,   272,   524,  2614,   261,  2064,\n",
       "          1645,   277,   273,   484,   308, 19962,   879,  1237,   284, 40231,\n",
       "           756,  3643,   275,  9313,   896,  2873,  4830,   433,   845, 20347,\n",
       "           401,   762,   259,  2934,   277, 23399,  6249, 23757,  6839,   756,\n",
       "           327,   629,  6928,   307,   287,   845,   896,  3354,  1216,   762,\n",
       "          1237,   365,   907,   272,   524,  2614,   261,   264,   399,  3050,\n",
       "           384,  8549,   307,  9313, 24714,  1522,   510, 36850,   267, 11037,\n",
       "         26897,  3840,   527,  4492,   524,  4072,  1037, 14964,  4201,   307,\n",
       "           730, 13566, 10495,   365,  2098,  1244,   259,   776,  1199,  8732,\n",
       "           627,   261,  2992,  1444,  3948,   277,  4886,   730,  1237,   287,\n",
       "          5828, 18184,   277,  1331,  3298,   307,   261,   277, 23399,   336,\n",
       "           324,   488,   907,  2160,   496, 24461, 34699,   286,  5613,   627,\n",
       "          3050,  1332,   606,  8843,   380, 20372,   269,   827,   908,   394,\n",
       "           454,   277, 23399,  1584,  2354,   264,  6781,   714,  4709, 11176,\n",
       "           488,  4795,  4731,   399,  5526, 24803,   629,   730,   365,  2098,\n",
       "          1339,  1199,  8732,   627, 11623,   277,  5712,   730,  4967, 36980,\n",
       "          9723,  5526,   400,  2195,  4571,  5399, 21184,   273,   762,  1237,\n",
       "          4313,   907,  1604,   261,  7101,   287,  7972,  1216,  7789,  1237,\n",
       "           327,   724, 27810,   730,  1237, 11968,  4313,  6249,   307,   287,\n",
       "          5828, 18184,   896,  3354,  1645,  2674,  1044,   329, 23038,   273,\n",
       "           896,  3354,   259,   720,  1421,   277, 10869, 24684,  5210,   284,\n",
       "          1245,  1685, 30551,  1216,  1237,  8549, 12480,  3014,   510,   762,\n",
       "          4830,   399,  1917,  2724,   329,   730,   365,  2098,   886,   259,\n",
       "           876,  1199,  8732,   627, 19962,   879,  1237,   277, 23399,   336,\n",
       "           586,   606,  1237, 32970,  6249,   307,   284, 40231,   756,  3643,\n",
       "           275,  9313,   896,  2873,  4830,   259, 28240,   433,   798,   762,\n",
       "          4830,   399,  1917,  3948,  3648,  5830,   261,   272, 11669, 21837,\n",
       "           365,  2098,   776,  1199,  8732,   627,   762,  1237,   277,   273,\n",
       "           275,   748,  4660,  5327,   275,   261,   358,  6897,   277,   320,\n",
       "           401,   287,  7843, 17291,   488,   907, 26782,   260, 22006,   461,\n",
       "          1430,   461,  2881,   307,  1645,  1037,  7720, 38786,  1137,  1628,\n",
       "          3948,  3648,  1216,   292,   829,  2944,   261,   264,   399,  3050,\n",
       "          1332,   259,  1496,   641,   384, 21754,   275,   261,   294,  2249,\n",
       "          5526,     1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is T5 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "model = AutoModelWithLMHead.from_pretrained('t5-base', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(\"summarize: \" + article_text,\n",
    "return_tensors='pt',\n",
    "max_length=512,\n",
    "truncation=True)\n",
    "summary_ids = model.generate(inputs, max_length=150, min_length=80, length_penalty=5., num_beams=2)\n",
    "summary = tokenizer.decode(summary_ids[0])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> the Monetary Authority of Singapore (MAS) recorded its largest net loss of S$3\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Keywords: \" + article_text,\n",
    "return_tensors='pt',\n",
    "max_length=512,\n",
    "truncation=True)\n",
    "# summary_ids = model.generate(inputs, max_length=150, min_length=80, length_penalty=5., num_beams=2)\n",
    "summary_ids = model.generate(inputs, no_repeat_ngram_size=5, num_beams=4)\n",
    "summary = tokenizer.decode(summary_ids[0])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
